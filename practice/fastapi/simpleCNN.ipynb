{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4388f1-7eac-4d82-8e4c-9c8388bab79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Input:  [B, 3, 224, 224]\n",
    "    Output: [B, 2] (logits for ['dog','cat'])\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 2, p_drop: float = 0.2):\n",
    "        super().__init__()\n",
    "        def block(cin, cout):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(cout),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(cout, cout, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(cout),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(2)  # downsample by 2\n",
    "            )\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            block(3,   32),   # 224 -> 112\n",
    "            nn.Dropout(p_drop),\n",
    "            block(32,  64),   # 112 -> 56\n",
    "            nn.Dropout(p_drop),\n",
    "            block(64, 128),   # 56  -> 28\n",
    "            nn.Dropout(p_drop),\n",
    "            block(128, 256),  # 28  -> 14\n",
    "            nn.Dropout(p_drop),\n",
    "        )\n",
    "        # global average pooling to 1×1\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "        # Kaiming init for convs\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)          # [B, 256, 14, 14]\n",
    "        x = self.gap(x)               # [B, 256, 1, 1]\n",
    "        x = torch.flatten(x, 1)       # [B, 256]\n",
    "        x = self.classifier(x)        # [B, 2] (logits)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e050b3-3e40-4c78-8d09-b929854cbc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.7680 | val_acc=0.5000\n",
      "Epoch 02 | train_loss=0.5878 | val_acc=0.6000\n",
      "Epoch 03 | train_loss=0.5763 | val_acc=0.5000\n",
      "Epoch 04 | train_loss=0.5178 | val_acc=0.5000\n",
      "Epoch 05 | train_loss=0.4887 | val_acc=0.5000\n",
      "Epoch 06 | train_loss=0.4563 | val_acc=0.5000\n",
      "Epoch 07 | train_loss=0.4105 | val_acc=0.5000\n",
      "Epoch 08 | train_loss=0.3838 | val_acc=0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m correct = total = \u001b[32m0\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1470\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1468\u001b[39m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent_workers:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1473\u001b[39m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[32m   1474\u001b[39m \n\u001b[32m   1475\u001b[39m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1618\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1613\u001b[39m         \u001b[38;5;28mself\u001b[39m._mark_worker_as_unavailable(worker_id, shutdown=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1614\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._workers:\n\u001b[32m   1615\u001b[39m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[32m   1616\u001b[39m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1618\u001b[39m     \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_queues:\n\u001b[32m   1620\u001b[39m     q.cancel_join_thread()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/multiprocessing/process.py:149\u001b[39m, in \u001b[36mBaseProcess.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parent_pid == os.getpid(), \u001b[33m'\u001b[39m\u001b[33mcan only join a child process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcan only join a started process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_popen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     _children.discard(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/multiprocessing/popen_fork.py:41\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     42\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/multiprocessing/connection.py:1148\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1148\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1149\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1150\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_ktbai/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import transforms\n",
    "\n",
    "# from models.cnn import SmallCNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Match FastAPI preprocessing: ToTensor -> [-1, 1]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Directory layout:\n",
    "# data/\n",
    "#   train/\n",
    "#     dog/*.jpg\n",
    "#     cat/*.jpg\n",
    "#   val/\n",
    "#     dog/*.jpg\n",
    "#     cat/*.jpg\n",
    "train_ds = datasets.ImageFolder('data/train', transform=train_tf)\n",
    "val_ds   = datasets.ImageFolder('data/val',   transform=val_tf)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = SmallCNN(num_classes=2).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "best_acc, epochs = 0.0, 20\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item() * x.size(0)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.numel()\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={running/len(train_ds):.4f} | val_acc={val_acc:.4f}\")\n",
    "\n",
    "    # keep best\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        os.makedirs('pts', exist_ok=True)\n",
    "        # torch.save(model.state_dict(), 'pts/model.pt') \n",
    "        # torch.save(model, './pts/model.pt')\n",
    "print(f\"Best val_acc = {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db489d-1eec-435c-a367-1e4946bd8582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d16962-2c91-4894-a336-47cb65f06a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxscript\n",
      "  Downloading onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ml_dtypes (from onnxscript)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxscript) (2.3.3)\n",
      "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
      "  Downloading onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting onnx>=1.16 (from onnxscript)\n",
      "  Downloading onnx-1.19.1-cp313-cp313-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: packaging in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxscript) (25.0)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxscript) (4.15.0)\n",
      "Collecting protobuf>=4.25.1 (from onnx>=1.16->onnxscript)\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Downloading onnxscript-0.5.6-py3-none-any.whl (683 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.0/683.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnx_ir-0.1.12-py3-none-any.whl (129 kB)\n",
      "Downloading ml_dtypes-0.5.3-cp313-cp313-macosx_10_13_universal2.whl (663 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.8/663.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.19.1-cp313-cp313-macosx_12_0_universal2.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Installing collected packages: protobuf, ml_dtypes, onnx, onnx_ir, onnxscript\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [onnxscript]5\u001b[0m [onnxscript]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ml_dtypes-0.5.3 onnx-1.19.1 onnx_ir-0.1.12 onnxscript-0.5.6 protobuf-6.33.0\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.23.2-cp313-cp313-macosx_13_0_arm64.whl.metadata (5.1 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxruntime) (2.3.3)\n",
      "Requirement already satisfied: packaging in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: protobuf in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxruntime) (6.33.0)\n",
      "Requirement already satisfied: sympy in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from onnxruntime) (1.14.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/goorm/miniconda3/envs/env_ktbai/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.23.2-cp313-cp313-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [onnxruntime]\u001b[0m [onnxruntime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 onnxruntime-1.23.2\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxscript\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a29a3d-7fcd-4d61-9c17-a4cb8edc3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "torch.onnx.export(model, dummy_input, \"./pts/model_from_torch.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fff75d-be4a-4b0a-9bb5-d78856911e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ktbai",
   "language": "python",
   "name": "env_ktbai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
