## Gemma 3 Multimodal Memory Stress Test

이 프로젝트는 로컬 LLM인 Gemma 3 (via Ollama)의 멀티모달(Vision) 능력과 Context Window(기억 용량)의 한계를 테스트하기 위해 제작됨.

일반적인 챗봇 개발 모범 사례(Best Practice)와 달리, 의도적으로 과거의 모든 이미지 데이터를 대화 기록에 누적시켜 모델의 환각(Hallucination) 증세와 메모리 한계를 관찰하도록 설계되었음.

### 실험 목적 (Objective)

보통의 멀티모달 챗봇은 성능과 비용 최적화를 위해 **'현재 턴의 이미지'**만 전송하고 과거 이미지는 텍스트로 요약하거나 삭제.

Context Retention: 모델은 과거에 업로드한 이미지를 몇 장까지 정확하게 기억할까?

Hallucination: 서로 다른 이미지가 계속 쌓일 때, 모델은 과거의 이미지와 현재의 이미지를 혼동하지 않을까?

System Limits: 로컬 환경에서 이미지(Base64/Bytes) 데이터가 계속 쌓일 때 응답 속도 저하와 컨텍스트 초과는 언제 발생하는가?

### 주요 기능

이미지 영구 보존 (Persistent Context): 업로드된 모든 이미지를 세션 기록(Session State)에 바이트(Byte) 형태로 텍스트와 함께 저장하고, 매 턴마다 전체 기록을 모델에 재전송.

모델을 극한의 상황으로 몰아넣음

질문의 경우 한글과 영어를 섞어서 언어별 속도차이도 실험

### 실행

streamlit run app.py

streamlit run app_test.py


### 실험 시나리오 및 결과 (Test Scenarios & Results)

app.py에서는 이미지를 세션기록에 포함하지 않고 해당 질문에서만 소비를 함 

-> 턴오버시 발생할 수 있는 문제들을 방지

app_test.py에서는 모델의 한계를 경험하기 위해 과거 이미지, 텍스트 데이터를 모두 세션기록에 저장

-> 대략 5~6장과 다른 질문들을 섞게되면 과거를 기억하지 못하고, 이미지와 텍스트 질문들이 쌓일수록 모델의 답변속도가 느려지고 영어보다 한국어로 질문했을 때 느림..

오래된 이야기, 이미지를 먼저 순차적으로 잃고 이미지의 경우 통째로 잃어버림

중간중간 업로드하지않은 이미지에 대해서 설명하는 현상도 발견..

### 파일 구조

.

├── app.py  # 메인 애플리케이션 코드

├── app_test.py  # 메인 애플리케이션 코드

└── README.md   # 프로젝트 설명서
