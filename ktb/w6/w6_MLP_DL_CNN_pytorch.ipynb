{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8321d6-d80a-474a-a999-bce6fd1bccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] range\n",
    "])\n",
    "\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ba0da3-31d9-42c8-b397-1fe9875032bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # Input: flattened image, Hidden: 128 units\n",
    "        self.fc2 = nn.Linear(128, 10)       # Output: 10 classes (0-9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation\n",
    "        x = self.fc2(x)  # No activation here, as we'll use CrossEntropyLoss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c521b648-7d3c-4f62-9cf8-97ff1f05c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e071607-8985-4722-80e1-72efdfe5b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Input channels: 1 (grayscale)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 pooling\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # After two pools: 28/4 = 7\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360088e3-a012-4c93-b0cd-fcf69e2d0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"{model_name} - Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1955bdd-f651-4fce-acf9-6234bb9b1559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Epoch 1, Loss: 0.3835\n",
      "MLP - Epoch 2, Loss: 0.1954\n",
      "MLP - Epoch 3, Loss: 0.1402\n",
      "MLP - Epoch 4, Loss: 0.1143\n",
      "MLP - Epoch 5, Loss: 0.0973\n",
      "MLP Test Accuracy: 97.16%\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(); train_and_evaluate(mlp, 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ff0470-96e5-462a-93e1-bcd214f91b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL - Epoch 1, Loss: 0.0883\n",
      "DL - Epoch 2, Loss: 0.0764\n",
      "DL - Epoch 3, Loss: 0.0705\n",
      "DL - Epoch 4, Loss: 0.0634\n",
      "DL - Epoch 5, Loss: 0.0569\n",
      "DL Test Accuracy: 97.59%\n"
     ]
    }
   ],
   "source": [
    "dl = DeepMLP(); train_and_evaluate(mlp, 'DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2901e2e-1565-45f6-8258-f19b8e6eff6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN - Epoch 1, Loss: 0.0549\n",
      "CNN - Epoch 2, Loss: 0.0489\n",
      "CNN - Epoch 3, Loss: 0.0446\n",
      "CNN - Epoch 4, Loss: 0.0431\n",
      "CNN - Epoch 5, Loss: 0.0399\n",
      "CNN Test Accuracy: 97.24%\n"
     ]
    }
   ],
   "source": [
    "cnn = DeepMLP(); train_and_evaluate(mlp, 'CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709377bc-9b9d-4d2c-91b8-a650a8afb38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "MLP - Epoch 1, Loss: 0.9018\n",
      "MLP - Epoch 2, Loss: 0.4115\n",
      "MLP - Epoch 3, Loss: 0.3140\n",
      "MLP - Epoch 4, Loss: 0.2764\n",
      "MLP - Epoch 5, Loss: 0.2497\n",
      "MLP Test Accuracy: 96.40%\n",
      "DeepMLP - Epoch 1, Loss: 0.6386\n",
      "DeepMLP - Epoch 2, Loss: 0.2738\n",
      "DeepMLP - Epoch 3, Loss: 0.2164\n",
      "DeepMLP - Epoch 4, Loss: 0.1797\n",
      "DeepMLP - Epoch 5, Loss: 0.1656\n",
      "DeepMLP Test Accuracy: 95.80%\n",
      "CNN - Epoch 1, Loss: 0.2969\n",
      "CNN - Epoch 2, Loss: 0.0978\n",
      "CNN - Epoch 3, Loss: 0.0749\n",
      "CNN - Epoch 4, Loss: 0.0636\n",
      "CNN - Epoch 5, Loss: 0.0551\n",
      "CNN Test Accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Basic transform for normalization (used for test set)\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Augmented transform for training set\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),  # Why this degree range? What if you experimented with 15?\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # How does translation simulate real handwriting shifts?\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=augmented_transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=basic_transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Deep MLP Model\n",
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, model_name, epochs=5, device='cpu'):\n",
    "    model.to(device)  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"{model_name} - Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Main execution - let's run all models\n",
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    mlp = MLP()\n",
    "    train_and_evaluate(mlp, 'MLP', epochs=5, device=device)\n",
    "    \n",
    "    deep_mlp = DeepMLP()\n",
    "    train_and_evaluate(deep_mlp, 'DeepMLP', epochs=5, device=device)\n",
    "    \n",
    "    cnn = CNN()\n",
    "    train_and_evaluate(cnn, 'CNN', epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e040d8-ef47-4dcc-98cf-108dfbebfda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ktbai",
   "language": "python",
   "name": "env_ktbai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
